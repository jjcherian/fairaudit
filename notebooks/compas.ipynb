{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fairaudit import Auditor\n",
    "from fairaudit.groups import get_intersections\n",
    "from fairaudit.metrics import Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS data\n",
    "\n",
    "In this notebook, we will apply the certification and flagging tools to the COMPAS dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>race</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>score_text</th>\n",
       "      <th>sex</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>decile_score</th>\n",
       "      <th>is_recid</th>\n",
       "      <th>two_year_recid</th>\n",
       "      <th>c_jail_in</th>\n",
       "      <th>c_jail_out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-08-13 06:03:42</td>\n",
       "      <td>2013-08-14 05:41:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-26 03:45:27</td>\n",
       "      <td>2013-02-05 05:36:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-04-13 04:58:34</td>\n",
       "      <td>2013-04-14 07:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-30 04:50:18</td>\n",
       "      <td>2013-12-01 12:28:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>14</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-02-18 05:08:24</td>\n",
       "      <td>2014-02-24 12:18:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7209</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-11-22 05:18:27</td>\n",
       "      <td>2013-11-24 02:59:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7210</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>African-American</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-31 07:13:54</td>\n",
       "      <td>2014-02-02 04:03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7211</th>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>Greater than 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-13 05:48:01</td>\n",
       "      <td>2014-01-14 07:49:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7212</th>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>African-American</td>\n",
       "      <td>25 - 45</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-03-08 08:06:02</td>\n",
       "      <td>2014-03-09 12:18:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7213</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Less than 25</td>\n",
       "      <td>Low</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-06-28 12:16:41</td>\n",
       "      <td>2014-06-30 11:19:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6172 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age c_charge_degree              race          age_cat score_text  \\\n",
       "0      69               F             Other  Greater than 45        Low   \n",
       "1      34               F  African-American          25 - 45        Low   \n",
       "2      24               F  African-American     Less than 25        Low   \n",
       "5      44               M             Other          25 - 45        Low   \n",
       "6      41               F         Caucasian          25 - 45     Medium   \n",
       "...   ...             ...               ...              ...        ...   \n",
       "7209   23               F  African-American     Less than 25     Medium   \n",
       "7210   23               F  African-American     Less than 25        Low   \n",
       "7211   57               F             Other  Greater than 45        Low   \n",
       "7212   33               M  African-American          25 - 45        Low   \n",
       "7213   23               F          Hispanic     Less than 25        Low   \n",
       "\n",
       "         sex  priors_count  days_b_screening_arrest  decile_score  is_recid  \\\n",
       "0       Male             0                     -1.0             1         0   \n",
       "1       Male             0                     -1.0             3         1   \n",
       "2       Male             4                     -1.0             4         1   \n",
       "5       Male             0                      0.0             1         0   \n",
       "6       Male            14                     -1.0             6         1   \n",
       "...      ...           ...                      ...           ...       ...   \n",
       "7209    Male             0                     -1.0             7         0   \n",
       "7210    Male             0                     -1.0             3         0   \n",
       "7211    Male             0                     -1.0             1         0   \n",
       "7212  Female             3                     -1.0             2         0   \n",
       "7213  Female             2                     -2.0             4         1   \n",
       "\n",
       "      two_year_recid            c_jail_in           c_jail_out  \n",
       "0                  0  2013-08-13 06:03:42  2013-08-14 05:41:20  \n",
       "1                  1  2013-01-26 03:45:27  2013-02-05 05:36:53  \n",
       "2                  1  2013-04-13 04:58:34  2013-04-14 07:02:04  \n",
       "5                  0  2013-11-30 04:50:18  2013-12-01 12:28:56  \n",
       "6                  1  2014-02-18 05:08:24  2014-02-24 12:18:30  \n",
       "...              ...                  ...                  ...  \n",
       "7209               0  2013-11-22 05:18:27  2013-11-24 02:59:20  \n",
       "7210               0  2014-01-31 07:13:54  2014-02-02 04:03:52  \n",
       "7211               0  2014-01-13 05:48:01  2014-01-14 07:49:46  \n",
       "7212               0  2014-03-08 08:06:02  2014-03-09 12:18:04  \n",
       "7213               1  2014-06-28 12:16:41  2014-06-30 11:19:23  \n",
       "\n",
       "[6172 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deciles = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "keep_columns = [\"age\", \"c_charge_degree\", \"race\", \"age_cat\", \"score_text\", \"sex\", \"priors_count\", \n",
    "                \"days_b_screening_arrest\", \"decile_score\", \"is_recid\", \"two_year_recid\", \n",
    "                \"c_jail_in\", \"c_jail_out\"]\n",
    "\n",
    "df_deciles = df_deciles[keep_columns]\n",
    "\n",
    "# filter out rows that we do not have labels/scores for\n",
    "row_filter = (df_deciles[\"days_b_screening_arrest\"] <= 30) & (df_deciles[\"days_b_screening_arrest\"] >= -30)\n",
    "row_filter &= (df_deciles[\"is_recid\"] != -1) & (df_deciles[\"c_charge_degree\"] != \"O\") \n",
    "row_filter &= df_deciles[\"score_text\"] != \"NA\"\n",
    "df_deciles = df_deciles[row_filter]\n",
    "\n",
    "df_deciles\n",
    "\n",
    "group_feats = ['race', 'age_cat', 'sex'] # groups we will consider throughout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get racial features\n",
    "unique_races, race_inds = np.unique(df_deciles['race'].to_numpy(), return_inverse=True)\n",
    "race_features = race_inds.reshape(-1,1)\n",
    "\n",
    "# filter by binary prediction\n",
    "angwin_threshold = 5\n",
    "northpointe_threshold = 8\n",
    "high_risk_filter = df_deciles['decile_score'] >= angwin_threshold\n",
    "df_ppv = df_deciles[high_risk_filter] # filter to just high-risk offenders\n",
    "\n",
    "# inputs to auditor are constructed below\n",
    "x = race_features[high_risk_filter]\n",
    "y = df_ppv['two_year_recid'].to_numpy()\n",
    "races_ppv = get_intersections(x) # get group indicators\n",
    "z = races_ppv[:,2] # white indicators\n",
    "\n",
    "# measure positive predictive value relative to Caucasian ppv\n",
    "metric = Metric(\n",
    "    name=\"PPV_Caucasian\", \n",
    "    evaluation_function=lambda z, y : np.isclose(y, 1), \n",
    "    threshold_function=lambda z, y: np.mean(y[z == True])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Certifying positive predictive value\n",
    "\n",
    "In this section of the notebook, we verify the Northpointe Inc. analysis of COMPAS, which claims that the positive predictive value (PPV) of COMPAS is comparable between African-American and Caucasian defendants.\n",
    "\n",
    "### Groups - African-Americans only\n",
    "In the first cell, we lower bound the discrepancy between the COMPAS PPV for African-American defendants relative to Caucasian defendants.\n",
    "\n",
    "$$\\epsilon = \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X_{\\text{race}} = \\text{African-American} \\right) - \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X_{\\text{race}} = \\text{Caucasian} \\right)$$\n",
    "\n",
    "Running the cell outputs a 95%-lower confidence bound on $\\epsilon$. Note that this result is only for one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:01<00:00, 1822.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01874145481608773]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "races_ac = races_ppv[:,[0,2]] # select only Caucasian / African-American subgroups\n",
    "\n",
    "auditor = Auditor(x, y, z, metric)\n",
    "auditor.calibrate_groups(\n",
    "    alpha=0.05,\n",
    "    type='upper',\n",
    "    epsilon=None,\n",
    "    groups=races_ac,\n",
    "    bootstrap_params={'seed': 0, 'B': 2000}\n",
    ")\n",
    "bound, value, threshold = auditor.query_group(0) # African-American lower bound\n",
    "bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups - all races\n",
    "\n",
    "We now consider the same certification problem over all races. In particular, we issue simultaneously valid 95% confidence intervals for\n",
    "\n",
    "$$\\epsilon(G) = \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X_{\\text{race}} = G \\right) - \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X_{\\text{race}} = \\text{Caucasian} \\right).$$\n",
    "\n",
    "To tighten the bound for smaller racial subgroups, we studentize the process by $(\\mathbb{P}_n(G) \\vee (25/n))^{3/2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1495.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-American: [0.013491  0.1011898]\n",
      "Asian: [-1.  1.]\n",
      "Caucasian: [-0.06681519  0.07535086]\n",
      "Hispanic: [-0.18299051  0.13286682]\n",
      "Native American: [-1.  1.]\n",
      "Other: [-0.20551123  0.24277097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# repeat this analysis but over all races\n",
    "prob_threshold = 25 / len(y)\n",
    "boot_params = {'seed': 0, 'B': 500, 'student': 'prob_bound', 'student_threshold': prob_threshold**(3/2)}\n",
    "\n",
    "auditor.calibrate_groups(\n",
    "    alpha=0.05,\n",
    "    type='interval',\n",
    "    epsilon=None,\n",
    "    groups=races_ppv,\n",
    "    bootstrap_params=boot_params\n",
    ")\n",
    "\n",
    "for grp_idx in range(races_ppv.shape[1]):\n",
    "    race = df_ppv['race'][races_ppv[:,grp_idx]].unique()[0]\n",
    "    bound_list, val_list, threshold_list = auditor.query_group(grp_idx)\n",
    "    clipped_bound = np.clip(bound_list[0], -1, 1)\n",
    "    print(f\"{race}: {clipped_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups - all intersections\n",
    "\n",
    "We last consider the PPV certification problem over all groups formed by the intersection of race, gender, and age category. In particular, we issue simultaneously valid 95% confidence intervals for\n",
    "\n",
    "$$\\epsilon(G) = \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X \\in G \\right) - \\mathbb{P} \\left(Y = 1 \\mid f(X) = 1, X_{\\text{race}} = \\text{Caucasian} \\right).$$\n",
    "\n",
    "To tighten the bound for smaller subgroups, we again studentize the process by $(\\mathbb{P}_n(G) \\vee (25/n))^{3/2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's include any intersection of race, age, and sex\n",
    "unique_races, race_inds = np.unique(df_ppv['race'].to_numpy(), return_inverse=True)\n",
    "unique_ages, age_inds = np.unique(df_ppv['age_cat'].to_numpy(), return_inverse=True)\n",
    "unique_sexes, sex_inds = np.unique(df_ppv['sex'].to_numpy(), return_inverse=True)\n",
    "\n",
    "x = np.concatenate(\n",
    "    (race_inds.reshape(-1,1), age_inds.reshape(-1,1), sex_inds.reshape(-1,1)), \n",
    "    axis=1\n",
    ")\n",
    "groups_ppv = get_intersections(x)\n",
    "\n",
    "prob_threshold = 25 / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 999.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African-American']: [0.010874097198480079, 0.10145035488519238]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']: [-0.00794314730153619, 0.08889829177864567]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']: [0.019496021771496994, 0.10070995149476372]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']: [-0.002414859526386433, 0.1149687029950463]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' 'Less than 25']: [-0.012219424196002915, 0.15161883387208408]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' 'Male']: [0.030111125557032978, 0.12828070252791318]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45' 'Male']: [0.001789770704694181, 0.10812710386080085]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Less than 25' 'Male']: [0.013809884196240102, 0.1603250692524798]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45' 'Male']: [0.011927112068647237, 0.138677059451921]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' 'Less than 25' 'Male']: [0.017018936585032535, 0.19782578785515292]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "auditor = Auditor(x, y, z, metric)\n",
    "\n",
    "boot_params = {'seed': 0, 'B': 500, 'student': 'prob_bound', 'student_threshold': prob_threshold**(3/2)}\n",
    "\n",
    "auditor.calibrate_groups(\n",
    "    alpha=0.05,\n",
    "    type='interval',\n",
    "    epsilon=None,\n",
    "    groups=groups_ppv,\n",
    "    bootstrap_params=boot_params\n",
    ")\n",
    "\n",
    "for group_ind in range(groups_ppv.shape[1]):\n",
    "    bound, metrics, thresholds = auditor.query_group(group_ind)\n",
    "    if np.asarray(bound).min() >= -0.015:\n",
    "        feats_filter = df_ppv[group_feats][groups_ppv[:,group_ind]].nunique() == 1\n",
    "        feats_filter = feats_filter.index[feats_filter]\n",
    "        group_identity = df_ppv[feats_filter][groups_ppv[:,group_ind]].drop_duplicates()\n",
    "        print(f\"{group_identity.values[0]}: {bound[0]}\\n{'-'*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test fairness\n",
    "\n",
    "Next, we consider certifying COMPAS under the \"test fairness\" criteria, i.e. that its calibration error is comparable across subgroups. This claim was first made heuristically by Chouldechova et al. (2016) in relation to the African-American and Caucasian subgroups. We simultaneously bound the calibration error over all subgroups and decile scores here.\n",
    "\n",
    "$$\\epsilon(G, s) = \\mathbb{P}(Y = 1 \\mid S = s, X \\in G) - \\mathbb{P}(Y = 1 \\mid S = s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare inputs to auditor\n",
    "\n",
    "unique_races, race_inds = np.unique(df_deciles['race'].to_numpy(), return_inverse=True)\n",
    "unique_ages, age_inds = np.unique(df_deciles['age_cat'].to_numpy(), return_inverse=True)\n",
    "unique_sexes, sex_inds = np.unique(df_deciles['sex'].to_numpy(), return_inverse=True)\n",
    "\n",
    "x = np.concatenate(\n",
    "    (race_inds.reshape(-1,1), age_inds.reshape(-1,1), sex_inds.reshape(-1,1)), \n",
    "    axis=1\n",
    ")\n",
    "y = df_deciles['two_year_recid'].to_numpy()\n",
    "z = df_deciles['decile_score'].to_numpy()\n",
    "\n",
    "groups = get_intersections(x)\n",
    "metric = Metric(\n",
    "    name=\"test_fairness\", \n",
    "    evaluation_function=lambda z, y: np.isclose(y, 1), \n",
    "    threshold_function=lambda z, y: np.mean(np.isclose(y, 1)), \n",
    "    metric_params={'calibration_bins' : np.unique(z)}\n",
    ")\n",
    "\n",
    "prob_threshold = (25 / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 342.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 342.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 348.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 364.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 362.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 377.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 383.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 385.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 382.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 380.64it/s]\n"
     ]
    }
   ],
   "source": [
    "auditor = Auditor(x, y, z, metric)\n",
    "boot_params = {'seed': 0, 'B': 500, 'student': 'prob_bound', \n",
    "               'student_threshold': prob_threshold**(3/2)}\n",
    "auditor.calibrate_groups(\n",
    "    alpha=0.1/len(np.unique(z)),\n",
    "    type='interval',\n",
    "    epsilon=None,\n",
    "    groups=groups,\n",
    "    bootstrap_params=boot_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we output a 90% confidence interval that is simultaneously valid over each $\\epsilon(G, s)$. To avoid outputting hundreds of confidence intervals, we only show the intervals for the $G$ over which we are able to certify that $\\max_{s} |\\epsilon(G, s)| \\leq 0.15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African-American']-1: [-0.05218049860518982, 0.08532643350355225]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-2: [-0.10411281943253475, 0.06076656459252128]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-3: [-0.054033563232977505, 0.13140556994879532]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-4: [-0.05942971459961753, 0.11313221337323515]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-5: [-0.08021130571737678, 0.0961454653208808]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-6: [-0.09220443129749896, 0.09510176341144862]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-7: [-0.0744162260380142, 0.09029436635123923]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-8: [-0.08482005181854839, 0.08470046253115679]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-9: [-0.06754737076179537, 0.09445111386738006]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American']-10: [-0.04273773713303043, 0.11099250414249573]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-1: [-0.028659206912197914, 0.07885945710550646]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-2: [-0.0655352986098128, 0.06105060761715533]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-3: [-0.10585347211675282, 0.06011975971201987]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-4: [-0.09521449503961173, 0.06815313631339692]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-5: [-0.10564487790970246, 0.06499630468611378]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-6: [-0.1063095243427264, 0.08718004982863226]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-7: [-0.06519403422965957, 0.11581882113350386]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-8: [-0.060846047385335195, 0.1270520865498761]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-9: [-0.07360609097018271, 0.11180380071300747]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['25 - 45']-10: [-0.10252724654995334, 0.06730328358652529]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-1: [-0.032575558155151556, 0.049480205620078425]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-2: [-0.02423676180373216, 0.09633684857741319]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-3: [-0.056532246338883915, 0.08563696063957237]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-4: [-0.055852219939773975, 0.08009177241527031]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-5: [-0.05217965390004846, 0.09640970244902881]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-6: [-0.05598938245488752, 0.10797203060243644]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-7: [-0.057550453337895366, 0.09273605040271923]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-8: [-0.0500905022194217, 0.1040635045507629]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-9: [-0.06253148497447021, 0.08802780259566773]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['Male']-10: [-0.057840764678271636, 0.08525329059853716]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-1: [-0.07235175354596658, 0.11203215038638256]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-2: [-0.1323916592788913, 0.05781150236334545]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-3: [-0.11069135217031514, 0.13927847881827043]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-4: [-0.10517803431377054, 0.12963610306066214]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-5: [-0.13125275746460635, 0.0934285081576936]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-6: [-0.14029815683403718, 0.10866177036619516]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-7: [-0.07924981944653844, 0.14032874157823494]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-8: [-0.08265029542917268, 0.13242211670693255]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-9: [-0.08162374628192988, 0.1315899201212817]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "['African-American' '25 - 45']-10: [-0.09493488987116869, 0.09610038606343606]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "scores = np.unique(z)\n",
    "for g_ind in range(groups.shape[1]):\n",
    "    bound_list, metrics, thresholds = auditor.query_group(g_ind)\n",
    "    if np.abs(bound_list).max() < 0.15:\n",
    "        feats_filter = df_deciles[group_feats][groups[:,g_ind]].nunique() == 1\n",
    "        feats_filter = feats_filter.index[feats_filter]\n",
    "        group_identity = df_deciles[feats_filter][groups[:,g_ind]].drop_duplicates()\n",
    "        for score, bound in zip(scores, bound_list):\n",
    "            print(f\"{group_identity.values[0]}-{score}: {bound}\")\n",
    "            print('-'*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean certification\n",
    "\n",
    "Here we use the Boolean certification method to identify subgroups for which $\\max_{s} |\\epsilon(G, s)| \\leq 0.15$. \n",
    "\n",
    "We remark that this approach fails to identify the African-American / 25-45 subgroup that the bound certification method would have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 341.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 326.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 334.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 357.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 329.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 327.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 385.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 390.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 326.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 312.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 381.09it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 380.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 375.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 376.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 378.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 377.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 375.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 315.49it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 354.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 350.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African-American']\n",
      "['25 - 45']\n",
      "['Male']\n"
     ]
    }
   ],
   "source": [
    "boot_params = {'seed': 0, 'B': 500, 'student': 'prob_bool', \n",
    "               'student_threshold': prob_threshold**(1/2)}\n",
    "auditor.calibrate_groups(\n",
    "    alpha=0.1/len(np.unique(z)), # since we now have 10 scores\n",
    "    type='interval',\n",
    "    epsilon=0.15,\n",
    "    groups=groups,\n",
    "    bootstrap_params=boot_params\n",
    ")\n",
    "\n",
    "for g_ind in range(groups.shape[1]):\n",
    "    certificates, metrics, thresholds = auditor.query_group(\n",
    "     groups[:,g_ind]\n",
    "    )\n",
    "\n",
    "    if np.all(certificates):\n",
    "        feats_filter = df_deciles[group_feats][groups[:,g_ind]].nunique() == 1\n",
    "        feats_filter = feats_filter.index[feats_filter]\n",
    "        group_identity = df_deciles[feats_filter][groups[:,g_ind]].drop_duplicates()\n",
    "        print(group_identity.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flagging disparities\n",
    "\n",
    "### Localizing false positive rate disparities\n",
    "\n",
    "The original COMPAS investigation of Angwin et al. (2016) flagged African-American defendants for having a higher false positive rate when compared to Caucasian ones, i.e.\n",
    "\n",
    "$$\\mathbb{P}\\left(S \\geq 5 \\mid Y = 0, X_{\\text{race}} = \\text{African-American} \\right) > \\mathbb{P}\\left(S \\geq 5 \\mid Y = 0, X_{\\text{race}} = \\text{Caucasian} \\right)$$\n",
    "\n",
    "Here we ask if we can localize this false positive rate disparity to a more granular subset of defendants. If \n",
    "\n",
    "$$\\epsilon(G) = \\mathbb{P}\\left(S \\geq 5 \\mid Y = 0, X \\in G \\right) - \\mathbb{P}\\left(S \\geq 5 \\mid Y = 0\\right)$$\n",
    "\n",
    "then we flag $G$ if we can reject the null hypothesis that $\\epsilon(G) \\leq 0.05$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_filter = df_deciles['two_year_recid'] == 0\n",
    "df_fpr = df_deciles[false_filter]\n",
    "\n",
    "group_feats = ['race', 'age_cat', 'sex']\n",
    "unique_races, race_inds = np.unique(df_fpr['race'].to_numpy(), return_inverse=True)\n",
    "unique_ages, age_inds = np.unique(df_fpr['age_cat'].to_numpy(), return_inverse=True)\n",
    "unique_sexes, sex_inds = np.unique(df_fpr['sex'].to_numpy(), return_inverse=True)\n",
    "\n",
    "x = np.concatenate(\n",
    "    (race_inds.reshape(-1,1), age_inds.reshape(-1,1), sex_inds.reshape(-1,1)), \n",
    "    axis=1\n",
    ")\n",
    "y = df_fpr['two_year_recid'].to_numpy()\n",
    "z = (df_fpr['decile_score'] >= 5).to_numpy() # high-risk flag\n",
    "groups_fpr = get_intersections(x)\n",
    "groups_fpr = groups_fpr[:, np.any(groups_fpr, axis=0)] # exclude groups with no values in them\n",
    "\n",
    "metric = Metric(\n",
    "    name=\"fpr\", \n",
    "    evaluation_function=lambda z, y: np.isclose(z, 1),\n",
    "    threshold_function=lambda z, y: np.mean(np.isclose(z, 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 935.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['African-American']: 0.12067585280959826\n",
      "['Less than 25']: 0.23186406580088142\n",
      "['African-American' '25 - 45']: 0.11251147396863566\n",
      "['African-American' 'Less than 25']: 0.29163370530579724\n",
      "['Caucasian' 'Less than 25']: 0.18044015008001815\n",
      "['African-American' 'Male']: 0.13393791828072618\n",
      "['Less than 25' 'Female']: 0.3051372199191898\n",
      "['Less than 25' 'Male']: 0.20638499175519695\n",
      "['African-American' '25 - 45' 'Male']: 0.1351471900089206\n",
      "['African-American' 'Less than 25' 'Female']: 0.3269237122939175\n",
      "['African-American' 'Less than 25' 'Male']: 0.27957256367694605\n",
      "['Caucasian' 'Less than 25' 'Female']: 0.39729408266428784\n",
      "['Hispanic' 'Less than 25' 'Male']: 0.24077234353385307\n"
     ]
    }
   ],
   "source": [
    "auditor = Auditor(x, y, z, metric)\n",
    "\n",
    "boot_params = {'seed': 0, \"student\": \"mad\", \"student_threshold\": 1e-8, \n",
    "               \"prob_threshold\": 25 / len(x)}\n",
    "flags, metric_values = auditor.flag_groups(\n",
    "    groups_fpr, \n",
    "    type=\"lower\", \n",
    "    alpha=0.1, \n",
    "    epsilon=0.05, \n",
    "    bootstrap_params=boot_params\n",
    ")\n",
    "\n",
    "\n",
    "for g_ind in range(groups_fpr.shape[1]):\n",
    "    feats_filter = df_fpr[group_feats][groups_fpr[:,g_ind]].nunique() == 1\n",
    "    feats_filter = feats_filter.index[feats_filter]\n",
    "    group_identity = df_fpr[feats_filter][groups_fpr[:,g_ind]].drop_duplicates()\n",
    "    if flags[g_ind]:\n",
    "        print(f\"{group_identity.values[0]}: {metric_values[0, g_ind]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localizing PPV disparities\n",
    "\n",
    "The rebuttal from Northpointe claimed that COMPAS was fair if measured by PPV. Here, we see if it is possible to discover any positive predictive value disparities. Define\n",
    "\n",
    "$$\\epsilon(G) = \\mathbb{P}\\left(Y = 1 \\mid S \\geq 5, X \\in G \\right) - \\mathbb{P}\\left(Y = 1 \\mid S \\geq 5\\right)$$\n",
    "\n",
    "then we flag $G$ if we can reject the null hypothesis that $\\epsilon(G) \\geq -0.05$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by binary prediction\n",
    "angwin_threshold = 5\n",
    "northpointe_threshold = 8\n",
    "high_risk_filter = df_deciles['decile_score'] >= angwin_threshold\n",
    "df_ppv = df_deciles[high_risk_filter] # filter to just high-risk offenders\n",
    "\n",
    "# inputs to auditor are constructed below\n",
    "unique_races, race_inds = np.unique(df_ppv['race'].to_numpy(), return_inverse=True)\n",
    "unique_ages, age_inds = np.unique(df_ppv['age_cat'].to_numpy(), return_inverse=True)\n",
    "unique_sexes, sex_inds = np.unique(df_ppv['sex'].to_numpy(), return_inverse=True)\n",
    "\n",
    "x = np.concatenate(\n",
    "    (race_inds.reshape(-1,1), age_inds.reshape(-1,1), sex_inds.reshape(-1,1)), \n",
    "    axis=1\n",
    ")\n",
    "y = df_ppv['two_year_recid'].to_numpy()\n",
    "z = races_ppv[:,2] # white indicators\n",
    "groups_ppv = get_intersections(x)\n",
    "\n",
    "metric = Metric(\n",
    "    name=\"PPV_Average\", \n",
    "    evaluation_function=lambda z, y : np.isclose(y, 1), \n",
    "    threshold_function=lambda z, y: np.mean(np.isclose(y, 1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 954.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Female']: -0.11314602176748438\n",
      "['Less than 25' 'Female']: -0.18683897200147062\n",
      "['Caucasian' 'Less than 25' 'Female']: -0.2439878321758597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "auditor = Auditor(x, y, z, metric)\n",
    "boot_params = {'seed': 0, \"student\": \"mad\", \"student_threshold\": 1e-8,\n",
    "               \"prob_threshold\": 25 / len(x)}\n",
    "flags, metric_values = auditor.flag_groups(\n",
    "    groups_ppv, \n",
    "    type=\"upper\", \n",
    "    alpha=0.1, \n",
    "    epsilon=-0.05, \n",
    "    bootstrap_params=boot_params\n",
    ")\n",
    "\n",
    "for group_ind in range(groups_ppv.shape[1]):\n",
    "    if flags[group_ind]:\n",
    "        feats_filter = df_ppv[group_feats][groups_ppv[:,group_ind]].nunique() == 1\n",
    "        feats_filter = feats_filter.index[feats_filter]\n",
    "        group_identity = df_ppv[feats_filter][groups_ppv[:,group_ind]].drop_duplicates()\n",
    "        print(f\"{group_identity.values[0]}: {metric_values[0, group_ind]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d1e434c06752bcd863d5c530835f442629457dbccbd7eb5fc267ca5f533dbc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
